{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b9daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import jacobian, grad, hessian, vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a6c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rbf(gamma):\n",
    "    def kernel(x, y):\n",
    "        return jnp.exp(-gamma*jnp.sum((x-y)**2))\n",
    "    return kernel\n",
    "\n",
    "# For simpler autodiff tests\n",
    "def poly():\n",
    "    def f(x, y):\n",
    "        return jnp.sum(x**3 + 2*y**3)\n",
    "    def f1(x, y):\n",
    "        return jnp.dot(x**4, y**4)\n",
    "    return f1\n",
    "\n",
    "def get_jac(f, argnums):\n",
    "    def jacobian(x, y):\n",
    "        return jacobian(f, argnums=argnums)(x, y)\n",
    "    return jacobian\n",
    "\n",
    "def get_lap(f, argnums):\n",
    "    def laplacian(x, y):\n",
    "        return jnp.trace(hessian(f, argnums=argnums)(x, y))\n",
    "    return laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be14eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = get_rbf(gamma = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72f76c4",
   "metadata": {},
   "source": [
    "Now define the laplacian and bilaplacian functions. To ensure these functions work on batches of points (We want to evaluate kernel *matrices*) we can use vmap to vectorize them. In practice, we want to evaluate $k(X_{I}, X_{B})$ where $X_I: (n, d)$ and $X_B: (m, d)$ are the d-dimensional interior and boundary points, arranged in rows. The following functions should take $X_I$ and $X_B$ and return a matrix $f(X_I, X_B)$ satisfying $f(X_I, X_B)_{ij} = f((X_I)_i, (X_B)_j)$. \n",
    "\n",
    "\n",
    "Use vmap twice. The inner vectorization makes sure f works on arguments of the form $(x, X_I)$, and the outer one allows the first argument to also be a matrix. For instance, using vmap on $f(X_I, x)$ with in_axes = (0, None) means evaluating $f((X_I)_{i}, x)$ for each row $i$ of $X_I$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751db2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "227b3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_x = get_lap(k, argnums=0) # laplacian wrt to first input x\n",
    "bilap = get_lap(lap_x, argnums=1) # laplacian wrt to second input y\n",
    "\n",
    "# I want them to work on batches, but need all to go to all. So one to all, then all to one..?\n",
    "vec_lapx = vmap(vmap(lap_x, in_axes = (None,0)), in_axes=(0, None)) \n",
    "vec_bilap = vmap(vmap(bilap, in_axes = (None,0)), in_axes = (0, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ab6bafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 100)\n"
     ]
    }
   ],
   "source": [
    "key = jax.random.key(1039)\n",
    "\n",
    "I = 200\n",
    "B = 100\n",
    "\n",
    "X_I = jax.random.uniform(key, shape=(I, 2))\n",
    "X_B = jax.random.uniform(key, shape=(B, 2))\n",
    "\n",
    "print(vec_lapx(X_I, X_B).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
